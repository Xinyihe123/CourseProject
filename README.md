# CS410 CourseProject -- Reproduce a paper

# Documentation:

Team LARA

Datasets from http://times.cs.uiuc.edu/~wang296/Data/

References: 

Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Proceedings of ACM KDD 2011, pp. 618-626. DOI=10.1145/2020408.2020505

Hongning Wang, Yue Lu and Chengxiang Zhai. Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach. The 16th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'2010), p783-792, 2010.

The codes in LRR are downloaded from Internet. These are references. Source: Hongning Wang, Yue Lu and Chengxiang Zhai. Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach. The 16th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'2010), p783-792, 2010.




# Presentation: https://mediaspace.illinois.edu/media/t/1_fo2gtfej

## files:

clean.py: 
data preprocess: First we remove the reviews with any missing aspect rating or document length less than 50 words (to keep the content coverage of all possible aspects).  Then we  convert all the words into lower cases and remove punctuations and stop words.  In vocab.txt we write vocabulary appearance based on reviews. If a word appears in several times in the same review, it would only be counted as once.  We then filtered out words that have less than ten occurences.  

load.py: build matrix for reviews and generate results.

lara.py: The LARA model, mainly the aspect modeling part. Gererated the alpha and s, which are the review-level k dimensional( 7 for our data) aspect weight vector and rating vector. The overall rating for the review can be drawn from the Gaussian distribution with mean alpah.T dot product s, and variance delta.

Data: The test data we use, download from http://times.cs.uiuc.edu/~wang296/Data/: TripAdvisor Data Set: JSON

## Required packages:
numpy
scipy
nltk

## Run:
python3 lara.py

## Project Members:
Xinyi He
Weijiang Li
Dingsen Shi 
Qunyu Shen
Ziyuan Wei

We decided to work with another team to build this model since the challenge we were facing when trying to understand the methods and alogrithm are extremely hard. 

Implementation of Model:

This model involves more than ten parameters, some of them are generated by mutivariate Gaussian distribution, variational distribution, and multinomial distribution, and they are updated using gradient based method, which are hard to implement and transfer the complex math equations into codes.
We spend most of our time on reading and understanding the paper and the math methods in the paper. 

